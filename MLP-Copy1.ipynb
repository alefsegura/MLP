{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepara_dataset(data, y_collumns, sep=','):\n",
    "    \n",
    "    # Acquiring dataset data and class data\n",
    "    y = data.iloc[:,len(data.columns)-y_collumns: len(data.columns)]\n",
    "    y = np.array(y)\n",
    "    X = data.iloc[:,0:len(data.columns)-y_collumns]\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # Randomizing dataset\n",
    "    indices = np.random.choice(len(X), len(X), replace=False)\n",
    "    X_values = X[indices]\n",
    "    y_values = y[indices]\n",
    "    \n",
    "    # Creating an alias to dataset -> dataset.X and dataset.Y\n",
    "    dataset = namedtuple('datset', 'X Y')\n",
    "\n",
    "    return dataset(X=X_values, Y=y_values)\n",
    "\n",
    "\n",
    "class MLP:\n",
    "    \n",
    "    def __init__(self, hidden_units, n_classes, learning_rate, delta_error):\n",
    "        self.hidden_units = hidden_units\n",
    "        self.n_classes = n_classes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.delta_error = delta_error\n",
    "    \n",
    "    def train_test_split(self, dataset, train_size):              \n",
    "        # Computing the lenght of dataset\n",
    "        lenght = dataset.X.shape[0]\n",
    "\n",
    "        # Split dataset into train and test\n",
    "        x_train = dataset.X[0:int(train_size*lenght), :]\n",
    "        y_train = dataset.Y[0:int(train_size*lenght), :]\n",
    "        x_test = dataset.X[int(train_size*lenght):, :]\n",
    "        y_test = dataset.Y[int(train_size*lenght):, :]\n",
    "\n",
    "        # Creating an alias to train and test set\n",
    "        dataset = namedtuple('datset', 'X Y')\n",
    "        train = dataset(X=x_train, Y=y_train)\n",
    "        test = dataset(X=x_test, Y=y_test)\n",
    "\n",
    "        return train, test\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "\n",
    "    def predict(self, X):\n",
    "        train = self.train\n",
    "        test = self.test\n",
    "        hidden_weights = self.hidden_weights\n",
    "        output_weights = self.output_weights\n",
    "        y_hat, _ = self.forward(X, hidden_weights, output_weights)\n",
    "        return np.argmax(y_hat)\n",
    "    \n",
    "    def score(self):\n",
    "        train = self.train\n",
    "        test = self.test\n",
    "        counter = 0\n",
    "        for i in range(test.X.shape[0]):\n",
    "            y_hat = self.predict(test.X[i,:])\n",
    "            y = np.argmax(test.Y[i,:])\n",
    "            if y == y_hat:\n",
    "                counter += 1\n",
    "        return counter/test.X.shape[0]\n",
    "        \n",
    "    def forward(self, x, hidden_weights, output_weights):\n",
    "        f_net_h = []\n",
    "        # Apllying the weights on the hidden units\n",
    "        for i in range(len(hidden_weights)):\n",
    "            # if is the first hidden unit\n",
    "            if i == 0:\n",
    "                net = np.matmul(x, hidden_weights[i][:,0:len(x)].transpose()) + hidden_weights[i][:,-1]\n",
    "                f_net = self.sigmoid(net)\n",
    "            # if is the second or more hidden unit\n",
    "            else:\n",
    "                net = np.matmul(f_net_h[i-1], hidden_weights[i][:,0:len(f_net_h[i-1])].transpose()) + hidden_weights[i][:,-1]\n",
    "                f_net = self.sigmoid(net)\n",
    "            # store f_net of hidden layers\n",
    "            f_net_h.append(f_net) \n",
    "\n",
    "        # Computing the net function to the output layer\n",
    "        net = np.matmul(f_net_h[len(f_net_h)-1],output_weights[:,0:len(f_net_h[len(f_net_h)-1])].transpose()) + output_weights[:,-1]  \n",
    "        f_net_o = self.sigmoid(net)\n",
    "\n",
    "        return f_net_o, f_net_h\n",
    "\n",
    "    def backward(self, dataset, j, hidden_weights, output_weights, f_net_o, f_net_h, eta, hidden_units, momentum_h, momentum_o, n_classes):\n",
    "        x = dataset.X[j,:]\n",
    "        y = dataset.Y[j,:]\n",
    "\n",
    "        # Measuring the error\n",
    "        error = y - f_net_o\n",
    "\n",
    "        delta_o = error*f_net_o*(1-f_net_o)\n",
    "\n",
    "        # Computing the delta for the hidden units\n",
    "        delta_h = []\n",
    "        for i in range(len(hidden_units)-1, -1, -1):\n",
    "            if i == len(hidden_units)-1:\n",
    "                w_o = output_weights[: ,0:hidden_units[i]]\n",
    "                delta = (f_net_h[i]*(1-f_net_h[i]))*(np.matmul(delta_o, w_o))\n",
    "            else:\n",
    "                w_o = hidden_weights[i+1][:,0:hidden_units[i]]\n",
    "                delta = (f_net_h[i]*(1-f_net_h[i]))*(np.matmul(delta, w_o))\n",
    "\n",
    "            delta_h.insert(0,delta)\n",
    "\n",
    "        # Computing the delta and updating weights for the output layer\n",
    "        delta_o = delta_o[:, np.newaxis]\n",
    "        f_net_aux = np.concatenate((f_net_h[len(hidden_units)-1],np.ones(1)))[np.newaxis, :]\n",
    "        output_weights = output_weights - -2*eta*np.matmul(delta_o, f_net_aux) + momentum_o\n",
    "        momentum_o = -(-2)*eta*np.matmul(delta_o, f_net_aux)\n",
    "\n",
    "        # Updating the weights for the hidden layers\n",
    "        for i in range(len(hidden_units)-1, -1, -1):\n",
    "            delta = delta_h[i][:, np.newaxis]\n",
    "            f_net_aux = np.concatenate((f_net_h[i],np.ones(1)))[np.newaxis, :]            \n",
    "            if i == 0:\n",
    "                x_aux = np.concatenate((x,np.ones(1)))[np.newaxis, :]\n",
    "                hidden_weights[i] = hidden_weights[i] - -2*eta*np.matmul(delta, x_aux) + momentum_h[i]\n",
    "                momentum_h[i] = -(-2)*eta*np.matmul(delta, x_aux)\n",
    "            else:\n",
    "                f_net_aux = np.concatenate((f_net_h[i-1],np.ones(1)))[np.newaxis, :]\n",
    "                hidden_weights[i] = hidden_weights[i] - -2*eta*np.matmul(delta, f_net_aux) + momentum_h[i]\n",
    "                momentum_h[i] = -(-2)*eta*np.matmul(delta, f_net_aux)\n",
    "\n",
    "        # Measuring the error\n",
    "        error = sum(error*error)\n",
    "\n",
    "        # Returning the updated weights, the new error and the momentum parameters\n",
    "        return hidden_weights, output_weights, error, momentum_h, momentum_o\n",
    "\n",
    "    def fit(self, dataset, train_size, verbose=False):\n",
    "        hidden_units = self.hidden_units\n",
    "        n_classes = self.n_classes\n",
    "        learning_rate = self.learning_rate\n",
    "        delta_error = self.delta_error\n",
    "        \n",
    "        # Train-Test Split\n",
    "        train, test = self.train_test_split(dataset, train_size)\n",
    "\n",
    "        # Initializing the hidden layers and weights\n",
    "        hidden_layers = len(hidden_units)\n",
    "        momentum_o = 0\n",
    "        momentum_h = []\n",
    "        hidden_weights = []\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            if i==0:\n",
    "                aux = np.zeros((hidden_units[i], dataset.X.shape[1] + 1))\n",
    "            else:\n",
    "                aux = np.zeros((hidden_units[i], hidden_units[i-1] + 1))\n",
    "            hidden_weights.append(aux)\n",
    "            momentum_h.append(aux)\n",
    "\n",
    "        # Filling the hidden layers weight values with a normal distribution between -1 and 1\n",
    "        for i in range(hidden_layers):\n",
    "            for j in range(hidden_units[i]):\n",
    "                if i==0:\n",
    "                    for k in range(dataset.X.shape[1] + 1):\n",
    "                        hidden_weights[i][j][k] = random.uniform(-1, 1)\n",
    "                else:\n",
    "                    for k in range(hidden_units[i-1]+1):\n",
    "                        hidden_weights[i][j][k] = random.uniform(-1, 1)\n",
    "\n",
    "        # Initializing and filling the weights values of output layer\n",
    "        output_weights = np.zeros((n_classes, hidden_units[len(hidden_units)-1]+1))\n",
    "        for i in range(n_classes):\n",
    "            for j in range(hidden_units[hidden_layers-1]+1):\n",
    "                output_weights[i][j] = random.uniform(-1, 1)\n",
    "\n",
    "        # Epochs\n",
    "        if verbose:\n",
    "            print('Epoch | Erro')\n",
    "        epoch = 0\n",
    "        errors_list = [1,0]\n",
    "        delta = 10\n",
    "        while(abs(delta) > delta_error):\n",
    "            sum_errors = 0\n",
    "            for i in range(1,train.X.shape[0]):\n",
    "                # Forward\n",
    "                f_net_o, f_net_h = self.forward(train.X[i,:], hidden_weights, output_weights)      \n",
    "                # Backward\n",
    "                hidden_weights,output_weights,error,momentum_h,momentum_o = self.backward(train,i,hidden_weights,output_weights,f_net_o,f_net_h,learning_rate,hidden_units,momentum_h,momentum_o,n_classes)\n",
    "                sum_errors += error\n",
    "            errors_list.append(sum_errors)\n",
    "            delta = errors_list[-1] - errors_list[-2]\n",
    "            if verbose:\n",
    "                print(' ', epoch, '  |', sum_errors)\n",
    "            epoch += 1\n",
    "        \n",
    "        if not verbose:\n",
    "            print('Last epoch: {} | Error: {}'.format(epoch, sum_errors))\n",
    "            \n",
    "        self.hidden_weights = hidden_weights\n",
    "        self.output_weights = output_weights\n",
    "        self.train = train\n",
    "        self.test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "# Reconhecendo dígitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last epoch: 48 | Error: 17.27279719657308\n",
      "\n",
      "Acurácia: 0.897489539748954\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Leitura do csv\n",
    "df = pd.read_csv('semeion.data', sep=' ', lineterminator='\\n', header=None)\n",
    "\n",
    "# Preparação do dataset\n",
    "digitos = prepara_dataset(df, 10)\n",
    "\n",
    "# Treinamento da rede\n",
    "mlp = MLP(hidden_units=[30], n_classes=10, learning_rate=0.5, delta_error=1e-2)\n",
    "mlp.fit(digitos, train_size=0.7)\n",
    "\n",
    "# Score\n",
    "print('\\nAcurácia:', mlp.score())\n",
    "\n",
    "# Resultado\n",
    "plt.figure(figsize=(20,5))\n",
    "for i in range(1,8):\n",
    "    plt.subplot(1,8,i)\n",
    "    rand = np.random.randint(0, len(dataset)+1)\n",
    "    real = np.argmax(digitos.Y[rand])\n",
    "    pred = mlp.predict(digitos.X[rand])\n",
    "    plt.imshow(digitos.X[rand].reshape(16,16), cmap='binary')\n",
    "    plt.xlabel('Real: {}\\nPrevisto: {}'.format(real, pred))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

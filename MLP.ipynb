{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    processing: Function that transform divides the dataset in train and test and transform the Y values in binary, OneHotEnconding\n",
    "\"\"\"\n",
    "def processing(X, y, percentage):\n",
    "    \n",
    "    # Normalizing \n",
    "    #x = StandardScaler().fit_transform(X) \n",
    "\n",
    "    # Labelizing \n",
    "    #y = y.reshape(len(y), 1)\n",
    "    #y = OneHotEncoder(sparse=False).fit_transform(y)\n",
    "        \n",
    "    # Computing the lenght of dataset\n",
    "    lenght = X.shape[0]\n",
    "\n",
    "    # Split dataset into train and test.\n",
    "    X_train = X[0:int(percentage*lenght), :]\n",
    "    y_train = y[0:int(percentage*lenght), :]\n",
    "\n",
    "    X_test = X[int(percentage*lenght):, :]\n",
    "    y_test = y[int(percentage*lenght):, :]\n",
    "        \n",
    "    #creating an alias to train and test set.\n",
    "    #dataset = namedtuple('datset', 'X Y')\n",
    "    #train = dataset(X=x_train, Y=y_train)\n",
    "    #test = dataset(X=x_test, Y=y_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    sigmoid: Function that applies the sigmoid function, used in the backpropagation step.\n",
    "\"\"\" \n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    mlp_forward: Function that is responsible for the forward step, that applies the actual weight values on the net.\n",
    "\"\"\"\n",
    "def mlp_forward(x, hidden_weights, output_weights):\n",
    "\n",
    "    f_net_h = []\n",
    "    #apllying the weights on the hidden units.\n",
    "    for i in range(len(hidden_weights)):\n",
    "        #if is the first hidden unit.\n",
    "        if i == 0:\n",
    "            net = np.matmul(x,hidden_weights[i][:,0:len(x)].transpose()) + hidden_weights[i][:,-1]\n",
    "            f_net = sigmoid(net)\n",
    "        #if is the second or more hidden unit\n",
    "        else:\n",
    "            net = np.matmul(f_net_h[i-1],hidden_weights[i][:,0:len(f_net_h[i-1])].transpose()) + hidden_weights[i][:,-1]\n",
    "            f_net = sigmoid(net)\n",
    "        \n",
    "        #store f_net of hidden layers.\n",
    "        f_net_h.append(f_net) \n",
    "\n",
    "    #computing the net function to the output layer.\n",
    "    net = np.matmul(f_net_h[len(f_net_h)-1],output_weights[:,0:len(f_net_h[len(f_net_h)-1])].transpose()) + output_weights[:,-1]\n",
    "        \n",
    "    f_net_o = sigmoid(net)\n",
    "    \n",
    "    return f_net_o, f_net_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    mlp_backward: Function that is responsible for the backpropagation step, which corresponds to the updating of weights.\n",
    "\"\"\"\n",
    "def mlp_backward(dataset, j, hidden_weights, output_weights, f_net_o, f_net_h, eta, hidden_units, alpha, momentum_h, momentum_o, n_classes):\n",
    "\n",
    "    x = dataset.X[j,:]\n",
    "    y = dataset.Y[j,:]\n",
    "    \n",
    "    # Measuring the error\n",
    "    error = y - f_net_o\n",
    "    delta_o = error*f_net_o*(1-f_net_o)\n",
    "    \n",
    "    # Computing the delta for the hidden units\n",
    "    delta_h = []\n",
    "    for i in range(len(hidden_units)-1, -1, -1):\n",
    "\n",
    "        if(i == len(hidden_units)-1):\n",
    "            w_o = output_weights[: ,0:hidden_units[i]]\n",
    "            delta = (f_net_h[i]*(1-f_net_h[i]))*(np.matmul(delta_o, w_o))\n",
    "        else:\n",
    "            w_o = hidden_weights[i+1][:,0:hidden_units[i]]\n",
    "            delta = (f_net_h[i]*(1-f_net_h[i]))*(np.matmul(delta, w_o))\n",
    "\n",
    "        delta_h.insert(0,delta)\n",
    "    \n",
    "    # Computing the delta and updating weights for the output layer\n",
    "    delta_o = delta_o[:, np.newaxis]\n",
    "    f_net_aux = np.concatenate((f_net_h[len(hidden_units)-1],np.ones(1)))[np.newaxis, :]\n",
    "    output_weights = output_weights - -2*eta*np.matmul(delta_o, f_net_aux) + momentum_o\n",
    "    momentum_o = - -2*eta*np.matmul(delta_o, f_net_aux)\n",
    "    \n",
    "    # Cpdating the weights for the hidden layers\n",
    "    for i in range(len(hidden_units)-1, -1, -1):\n",
    "        delta = delta_h[i][:, np.newaxis]\n",
    "        f_net_aux = np.concatenate((f_net_h[i],np.ones(1)))[np.newaxis, :]    \n",
    "\n",
    "        if i == 0:\n",
    "            x_aux = np.concatenate((x,np.ones(1)))[np.newaxis, :]\n",
    "            hidden_weights[i] = hidden_weights[i] - -2*eta*np.matmul(delta, x_aux) + momentum_h[i]\n",
    "            momentum_h[i] = - -2*eta*np.matmul(delta, x_aux)\n",
    "        else:\n",
    "            f_net_aux = np.concatenate((f_net_h[i-1],np.ones(1)))[np.newaxis, :]\n",
    "            hidden_weights[i] = hidden_weights[i] - -2*eta*np.matmul(delta, f_net_aux) + momentum_h[i]\n",
    "            momentum_h[i] = - -2*eta*np.matmul(delta, f_net_aux)\n",
    "\n",
    "    # Measuring the error\n",
    "    error = sum(error*error)\n",
    "\n",
    "    # Return the updated weights, the new error and the momentum parameters.\n",
    "    return hidden_weights, output_weights, error, momentum_h, momentum_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    testing: Function that is responsible to realize the tests for the classification and regression methods\n",
    "             for different datasets.\n",
    "\"\"\"\n",
    "def testing(X_train, X_test, y_train, y_test, hidden_weights, output_weights):\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "        y_hat, q = mlp_forward(X_test[i,:], hidden_weights, output_weights)\n",
    "        y_hat = np.argmax(y_hat)\n",
    "        y = np.argmax(y_test[i,:])\n",
    "        if y == y_hat:\n",
    "            counter += 1\n",
    "\n",
    "    return counter/test.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    MLP: function that is responsible to initialize weights, check conditions to construct net.\n",
    "\"\"\"\n",
    "def MLP(X, y, hidden_units, epochs, eta, alpha, data_ratio):\n",
    "    n_classes = len(np.unique(y))\n",
    "    hidden_layers = len(hidden_units)\n",
    "    \n",
    "    # Acquiring the train and test set\n",
    "    #X_train, X_test, y_train, y_test = processing(X, y, data_ratio)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    # Initializing the weights of the hidden layers\n",
    "    momentum_o = 0\n",
    "    momentum_h = []\n",
    "    hidden_weights = []\n",
    "    for i in range(hidden_layers):\n",
    "        if(i == 0):\n",
    "            aux = np.zeros((hidden_units[i], X.shape[1] + 1))\n",
    "        else:\n",
    "            aux = np.zeros((hidden_units[i], hidden_units[i-1] + 1))\n",
    "        hidden_weights.append(aux)\n",
    "        momentum_h.append(aux)\n",
    "  \n",
    "    # Filling the hidden layers weight values with a normal distribution between -1 and 1\n",
    "    for i in range(hidden_layers):\n",
    "        for j in range(hidden_units[i]):\n",
    "            if(i == 0):\n",
    "                for k in range(X.shape[1] + 1):\n",
    "                    hidden_weights[i][j][k] = random.uniform(-1, 1)\n",
    "            else:\n",
    "                for k in range(hidden_units[i-1]+1):\n",
    "                    hidden_weights[i][j][k] = random.uniform(-1, 1)\n",
    "\n",
    "    # Initializing and filling the weights values of output layer\n",
    "    output_weights = np.zeros((n_classes, hidden_units[len(hidden_units)-1]+1))\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        for j in range(hidden_units[hidden_layers-1]+1):\n",
    "            output_weights[i][j] = random.uniform(-1, 1)\n",
    "\n",
    "    epoch = 0\n",
    "    for epoch in range(epochs):\n",
    "        print\n",
    "        sum_errors = 0\n",
    "        for i in range(train.X.shape[0]):\n",
    "            # Forward\n",
    "            f_net_o, f_net_h = mlp_forward(X_train[i, :], hidden_weights, output_weights)\n",
    "            # Backward hidden_weights, output_weights, error\n",
    "            hidden_weights, output_weights, error, momentum_h, momentum_o = mlp_backward(X_train, y_train, i, hidden_weights, output_weights, f_net_o, f_net_h, eta, hidden_units, alpha, momentum_h, momentum_o, n_classes)\n",
    "            sum_errors += error\n",
    "        epoch += 1\n",
    "\n",
    "    # Evaluating    \n",
    "    return testing(X_train, X_test, y_train, y_test, hidden_weights, output_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/wine.csv', index_col=False, header=None)\n",
    "X = np.array(data.iloc[:,:-1])\n",
    "y = np.array(data.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-e8226da03ca5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-3f47633de6f5>\u001b[0m in \u001b[0;36mMLP\u001b[1;34m(X, y, hidden_units, epochs, eta, alpha, data_ratio)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0msum_errors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[1;31m# Forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mf_net_o\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_net_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlp_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "indices = np.random.choice(len(X), len(X), replace=False)\n",
    "\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "MLP(X, y, hidden_units=(2,), epochs=100, eta=1e-2, alpha=2, data_ratio=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('semeion.data', sep=' ', lineterminator='\\n', header=None).iloc[:,:-1]\n",
    "X = dataset.iloc[:,:256].values\n",
    "y = dataset.iloc[:,256:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5dec451a054c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0meta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     data_ratio = 0.7)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-3f47633de6f5>\u001b[0m in \u001b[0;36mMLP\u001b[1;34m(X, y, hidden_units, epochs, eta, alpha, data_ratio)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0msum_errors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[1;31m# Forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mf_net_o\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_net_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlp_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "MLP(X,y,\n",
    "    hidden_units = (5,5),\n",
    "    epochs = 200,\n",
    "    eta = 1e-2,\n",
    "    alpha = 0.2,\n",
    "    data_ratio = 0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

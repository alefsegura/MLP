{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataset(filename, y_collumns, sep=','):\n",
    "    #  Reading the dataset\n",
    "    data = pd.read_csv(filename, sep=sep)\n",
    "    \n",
    "    # Acquiring dataset data and class data\n",
    "    y = data.iloc[:,len(data.columns)-y_collumns: len(data.columns)]\n",
    "    y = np.array(y)\n",
    "    X = data.iloc[:,0:len(data.columns)-y_collumns]\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # Randomizing dataset\n",
    "    indices = np.random.choice(len(X), len(X), replace=False)\n",
    "    X_values = X[indices]\n",
    "    y_values = y[indices]\n",
    "    \n",
    "    # Creating an alias to dataset -> dataset.X and dataset.Y\n",
    "    dataset = namedtuple('datset', 'X Y')\n",
    "\n",
    "    return dataset(X=X_values, Y=y_values)\n",
    "\n",
    "\n",
    "def train_test_split(dataset, train_size):              \n",
    "    # Computing the lenght of dataset\n",
    "    lenght = dataset.X.shape[0]\n",
    "\n",
    "    # Split dataset into train and test\n",
    "    x_train = dataset.X[0:int(train_size*lenght), :]\n",
    "    y_train = dataset.Y[0:int(train_size*lenght), :]\n",
    "    x_test = dataset.X[int(train_size*lenght):, :]\n",
    "    y_test = dataset.Y[int(train_size*lenght):, :]\n",
    "        \n",
    "    # Creating an alias to train and test set\n",
    "    dataset = namedtuple('datset', 'X Y')\n",
    "    train = dataset(X=x_train, Y=y_train)\n",
    "    test = dataset(X=x_test, Y=y_test)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "def testing(train, test, hidden_weights, output_weights):\n",
    "    counter = 0\n",
    "    for i in range(test.X.shape[0]):\n",
    "        y_hat, q = forward(test.X[i,:], hidden_weights, output_weights)\n",
    "        y_hat = np.argmax(y_hat)\n",
    "        y = np.argmax(test.Y[i,:])\n",
    "        if y == y_hat:\n",
    "            counter += 1\n",
    "    return counter/test.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, hidden_weights, output_weights):\n",
    "\n",
    "    f_net_h = []\n",
    "    \n",
    "    # Apllying the weights on the hidden units\n",
    "    for i in range(len(hidden_weights)):\n",
    "        \n",
    "        # if is the first hidden unit\n",
    "        if i == 0:\n",
    "            net = np.matmul(x, hidden_weights[i][:,0:len(x)].transpose()) + hidden_weights[i][:,-1]\n",
    "            f_net = sigmoid(net)\n",
    "            \n",
    "        # if is the second or more hidden unit\n",
    "        else:\n",
    "            net = np.matmul(f_net_h[i-1], hidden_weights[i][:,0:len(f_net_h[i-1])].transpose()) + hidden_weights[i][:,-1]\n",
    "            f_net = sigmoid(net)\n",
    "        \n",
    "        # store f_net of hidden layers\n",
    "        f_net_h.append(f_net) \n",
    "\n",
    "    # Computing the net function to the output layer\n",
    "    net = np.matmul(f_net_h[len(f_net_h)-1],output_weights[:,0:len(f_net_h[len(f_net_h)-1])].transpose()) + output_weights[:,-1]  \n",
    "    f_net_o = sigmoid(net)\n",
    "    \n",
    "    return f_net_o, f_net_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(dataset, j, hidden_weights, output_weights, f_net_o, f_net_h, eta, hidden_units, momentum_h, momentum_o, n_classes):\n",
    "\n",
    "    x = dataset.X[j,:]\n",
    "    y = dataset.Y[j,:]\n",
    "    \n",
    "    # Measuring the error\n",
    "    error = y - f_net_o\n",
    "    \n",
    "    delta_o = error*f_net_o*(1-f_net_o)\n",
    "        \n",
    "    # Computing the delta for the hidden units\n",
    "    delta_h = []\n",
    "    for i in range(len(hidden_units)-1, -1, -1):\n",
    "        if i == len(hidden_units)-1:\n",
    "            w_o = output_weights[: ,0:hidden_units[i]]\n",
    "            delta = (f_net_h[i]*(1-f_net_h[i]))*(np.matmul(delta_o, w_o))\n",
    "        else:\n",
    "            w_o = hidden_weights[i+1][:,0:hidden_units[i]]\n",
    "            delta = (f_net_h[i]*(1-f_net_h[i]))*(np.matmul(delta, w_o))\n",
    "\n",
    "        delta_h.insert(0,delta)\n",
    "    \n",
    "    # Computing the delta and updating weights for the output layer\n",
    "    delta_o = delta_o[:, np.newaxis]\n",
    "    f_net_aux = np.concatenate((f_net_h[len(hidden_units)-1],np.ones(1)))[np.newaxis, :]\n",
    "    output_weights = output_weights - -2*eta*np.matmul(delta_o, f_net_aux) + momentum_o\n",
    "    momentum_o = - -2*eta*np.matmul(delta_o, f_net_aux)\n",
    "    \n",
    "    # Updating the weights for the hidden layers\n",
    "    for i in range(len(hidden_units)-1, -1, -1):\n",
    "        delta = delta_h[i][:, np.newaxis]\n",
    "        f_net_aux = np.concatenate((f_net_h[i],np.ones(1)))[np.newaxis, :]            \n",
    "        if i == 0:\n",
    "            x_aux = np.concatenate((x,np.ones(1)))[np.newaxis, :]\n",
    "            hidden_weights[i] = hidden_weights[i] - -2*eta*np.matmul(delta, x_aux) + momentum_h[i]\n",
    "            momentum_h[i] = -(-2)*eta*np.matmul(delta, x_aux)\n",
    "        else:\n",
    "            f_net_aux = np.concatenate((f_net_h[i-1],np.ones(1)))[np.newaxis, :]\n",
    "            hidden_weights[i] = hidden_weights[i] - -2*eta*np.matmul(delta, f_net_aux) + momentum_h[i]\n",
    "            momentum_h[i] = -(-2)*eta*np.matmul(delta, f_net_aux)\n",
    "\n",
    "    # Measuring the error\n",
    "    error = sum(error*error)\n",
    "\n",
    "    # Returning the updated weights, the new error and the momentum parameters\n",
    "    return hidden_weights, output_weights, error, momentum_h, momentum_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(dataset, hidden_units, n_classes, learning_rate, train_size, delta_error):\n",
    "    \n",
    "    # Train-Test Split\n",
    "    train, test = train_test_split(dataset, train_size)\n",
    "\n",
    "    # Initializing the hidden layers and weights\n",
    "    hidden_layers = len(hidden_units)\n",
    "    momentum_o = 0\n",
    "    momentum_h = []\n",
    "    hidden_weights = []\n",
    "\n",
    "    for i in range(hidden_layers):\n",
    "        if i==0:\n",
    "            aux = np.zeros((hidden_units[i], dataset.X.shape[1] + 1))\n",
    "        else:\n",
    "            aux = np.zeros((hidden_units[i], hidden_units[i-1] + 1))\n",
    "        hidden_weights.append(aux)\n",
    "        momentum_h.append(aux)\n",
    "    \n",
    "    # Filling the hidden layers weight values with a normal distribution between -1 and 1\n",
    "    for i in range(hidden_layers):\n",
    "        for j in range(hidden_units[i]):\n",
    "            if i==0:\n",
    "                for k in range(dataset.X.shape[1] + 1):\n",
    "                    hidden_weights[i][j][k] = random.uniform(-1, 1)\n",
    "            else:\n",
    "                for k in range(hidden_units[i-1]+1):\n",
    "                    hidden_weights[i][j][k] = random.uniform(-1, 1)\n",
    "    \n",
    "    # Initializing and filling the weights values of output layer\n",
    "    output_weights = np.zeros((n_classes, hidden_units[len(hidden_units)-1]+1))\n",
    "    for i in range(n_classes):\n",
    "        for j in range(hidden_units[hidden_layers-1]+1):\n",
    "            output_weights[i][j] = random.uniform(-1, 1)\n",
    "    \n",
    "    # Epochs\n",
    "    print('Epoch | Erro')\n",
    "    epoch = 0\n",
    "    errors_list = [1,0]\n",
    "    delta = 10\n",
    "    while(abs(delta) > delta_error):\n",
    "        sum_errors = 0\n",
    "        for i in range(1,train.X.shape[0]):\n",
    "            # Forward\n",
    "            f_net_o, f_net_h = forward(train.X[i,:], hidden_weights, output_weights)      \n",
    "            # Backward\n",
    "            hidden_weights,output_weights,error,momentum_h,momentum_o = backward(train,i,hidden_weights,output_weights,f_net_o,f_net_h,learning_rate,hidden_units,momentum_h,momentum_o,n_classes)\n",
    "            sum_errors += error\n",
    "        errors_list.append(sum_errors)\n",
    "        delta = errors_list[-1] - errors_list[-2]\n",
    "        print(' ', epoch, '  |', sum_errors)\n",
    "        epoch += 1\n",
    "                \n",
    "    # Testando\n",
    "    return testing(train, test, hidden_weights, output_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### TESTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "digitos = readDataset(\"semeion.data\", 10, sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch | Erro\n",
      "  0   | 891.2513455648199\n",
      "  1   | 527.2322032521415\n",
      "  2   | 354.7171029820024\n",
      "  3   | 287.84832623142165\n",
      "  4   | 192.2861581734348\n",
      "  5   | 191.65195082246225\n",
      "  6   | 150.94851185816555\n",
      "  7   | 132.48494065621026\n",
      "  8   | 115.279726361014\n",
      "  9   | 109.55586163146236\n",
      "  10   | 78.71341872059574\n",
      "  11   | 75.973607137649\n",
      "  12   | 64.23139452947106\n",
      "  13   | 55.85423386219918\n",
      "  14   | 48.05326454421675\n",
      "  15   | 43.01927463726233\n",
      "  16   | 26.904361403171198\n",
      "  17   | 24.598098234038403\n",
      "  18   | 22.367413896499297\n",
      "  19   | 19.609608060900367\n",
      "  20   | 18.676614241782453\n",
      "  21   | 18.460847919047126\n",
      "  22   | 18.34053005764898\n",
      "  23   | 18.226652413646235\n",
      "  24   | 18.0840540603699\n",
      "  25   | 34.282402318844696\n",
      "  26   | 18.444175995231177\n",
      "  27   | 16.273165511919185\n",
      "  28   | 15.59406194318373\n",
      "  29   | 15.4420198713184\n",
      "  30   | 15.393730499949829\n",
      "  31   | 15.363420061230286\n",
      "  32   | 15.340079491241069\n",
      "  33   | 15.320643310081573\n",
      "  34   | 15.304390210439422\n",
      "  35   | 15.289937866879432\n",
      "  36   | 15.276801653601291\n",
      "  37   | 15.264609977759122\n",
      "  38   | 15.253143269751389\n",
      "  39   | 15.24217071484829\n",
      "  40   | 15.231457482829\n",
      "  41   | 15.220717965410199\n",
      "  42   | 15.2095614940927\n",
      "  43   | 15.197359534775439\n",
      "  44   | 15.182907069241054\n",
      "  45   | 15.163545055635053\n",
      "  46   | 15.134528870862638\n",
      "  47   | 15.058671664416591\n",
      "  48   | 14.809501569146079\n",
      "  49   | 14.423881198876865\n",
      "  50   | 14.312771376883644\n",
      "  51   | 14.274519395575897\n",
      "  52   | 14.25412579279603\n",
      "  53   | 14.2397544682014\n",
      "  54   | 14.228618388160083\n",
      "  55   | 14.219424520619043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8702928870292888"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP(digitos, hidden_units=[30], n_classes=10, learning_rate=0.5, train_size=0.7, delta_error=1e-2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
